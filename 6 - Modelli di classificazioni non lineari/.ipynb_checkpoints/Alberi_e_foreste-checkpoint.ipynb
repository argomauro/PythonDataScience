{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alberi decisonali e Foreste casuali\n",
    "In questo tutorial utilizzeremo alberi decisionali e foreste casuali per creare un modello di machine learning in grado di dirci se una determinata persona avrebbe avuto possibilità di salvarsi dal disastro del Titanic.<br>\n",
    "Importiamo le librerie necessarie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carichiamo il dataset dal sito della Standford University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 887 entries, 0 to 886\n",
      "Data columns (total 8 columns):\n",
      "Survived                   887 non-null int64\n",
      "Pclass                     887 non-null int64\n",
      "Name                       887 non-null object\n",
      "Sex                        887 non-null object\n",
      "Age                        887 non-null float64\n",
      "Siblings/Spouses Aboard    887 non-null int64\n",
      "Parents/Children Aboard    887 non-null int64\n",
      "Fare                       887 non-null float64\n",
      "dtypes: float64(2), int64(4), object(2)\n",
      "memory usage: 55.5+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic = pd.read_csv(\"http://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv\")\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il dataset contiene 887 esempi e 8 colonne, la colonna target è Survived, che contiene 1 nel caso in cui un utente si sia salvato, 0 altrimenti.\n",
    "Pclass e Fare sono proprietà interessanti, in quanto mostrano rispettivamente la classe ed il costo del biglietto per il Titanic.<br>\n",
    "La proprietà Name contiene il nome del passeggero ed è ininfluente per la il nostro modello, quindi scartiamola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.drop(\"Name\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eseguiamo il One Hot Encoding del DataFrame per dividere uomo/donna in due colonne diverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  Siblings/Spouses Aboard  Parents/Children Aboard  \\\n",
       "0         0       3  22.0                        1                        0   \n",
       "1         1       1  38.0                        1                        0   \n",
       "2         1       3  26.0                        0                        0   \n",
       "3         1       1  35.0                        1                        0   \n",
       "4         0       3  35.0                        0                        0   \n",
       "\n",
       "      Fare  Sex_female  Sex_male  \n",
       "0   7.2500           0         1  \n",
       "1  71.2833           1         0  \n",
       "2   7.9250           1         0  \n",
       "3  53.1000           1         0  \n",
       "4   8.0500           0         1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = pd.get_dummies(titanic)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adesso possiamo creare i nostri array Numpy per addestramento e predizione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = titanic.drop(\"Survived\", axis=1).values\n",
    "Y = titanic[\"Survived\"].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un vantaggio degli alberi decisionali è che non richiedono che i dati siano sulla stessa scala, quindi possiamo proseguire direttamente a creare il nostro modello."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alberi decisionali\n",
    "Gli alberi decisionali sono un modello di machine learning che permette di eseguire predizioni apprendendo una sequenza di domande dai dati.<br>\n",
    "Creiamo il nostro albero decisionale utilizzando sklearn e calcoliamo l'accuratezza delle predizioni su train e test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY: TRAIN=0.9806 TEST=0.7715\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion=\"gini\") #gini è il valore di default, quindi potremmo anche omettere il parametro\n",
    "tree.fit(X_train, Y_train)\n",
    "\n",
    "y_pred_train = tree.predict(X_train)\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "accuracy_train = accuracy_score(Y_train, y_pred_train)\n",
    "accuracy_test = accuracy_score(Y_test, y_pred)\n",
    "\n",
    "print(\"ACCURACY: TRAIN=%.4f TEST=%.4f\" % (accuracy_train,accuracy_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il nostro albero decisionale soffre di un problema di overfitting, dovuto probabilmente alla sua eccessiva profondità, tramite il parametro max_depth possiamo controllarne la profondità massima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY: TRAIN=0.8935 TEST=0.8090\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=6)\n",
    "tree.fit(X_train, Y_train)\n",
    "\n",
    "y_pred_train = tree.predict(X_train)\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "accuracy_train = accuracy_score(Y_train, y_pred_train)\n",
    "accuracy_test = accuracy_score(Y_test, y_pred)\n",
    "\n",
    "print(\"ACCURACY: TRAIN=%.4f TEST=%.4f\" % (accuracy_train,accuracy_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Molto meglio così! Un'altra caratteristica fantastica degli alberi decisionali è che possono essere visualizzati.\n",
    "Utilizziamo la funzione export_graphviz di sklearn per esportare l'albero in un file dot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "dotfile = open(\"tree.dot\", 'w')\n",
    "export_graphviz(tree, out_file = dotfile, feature_names = titanic.columns.drop(\"Survived\"))\n",
    "dotfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adesso prova ad apire il file con il programma Graphviz, oppure se non lo hai e non vuoi installarlo incolla il contenuto del file in [questo sito](http://webgraphviz.com/)<br>\n",
    "Dovresti ottenere qualcosa del genere.\n",
    "<img src=\"res/tree.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foreste casuali\n",
    "Le foresti casuali sono un modello appartenente alla categoria degli Esemble Method (modelli di insieme), esse permettono di creare diversi alberi decisionali e metterli insieme per ottenere un modello più robusto.<br>\n",
    "Creiamo la nostra foresta casuale utilizzando sklearn e calcoliamo l'accuratezza delle predizioni su train e test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY: TRAIN=0.9161 TEST=0.8577\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=30, max_depth=8, random_state=False)\n",
    "\n",
    "forest.fit(X_train, Y_train)\n",
    "\n",
    "y_pred_train = forest.predict(X_train)\n",
    "y_pred = forest.predict(X_test)\n",
    "\n",
    "accuracy_train = accuracy_score(Y_train, y_pred_train)\n",
    "accuracy_test = accuracy_score(Y_test, y_pred)\n",
    "\n",
    "print(\"ACCURACY: TRAIN=%.4f TEST=%.4f\" % (accuracy_train,accuracy_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
