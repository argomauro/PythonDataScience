{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ottimizzazione degli iperparametri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fase di ottimizzazione degli iperparametri, conosciuta in gergo tecnico come hyperparameters tuning, è la parte più ostica nel processo di creazione di un modello predittivo.<br>\n",
    "In questo notebook vedremo due tecniche che ci permettono di semplificare questo lavoro.<br>\n",
    "Importiamo le librerie necessarie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carichiamo l'Iris Dataset all'interno di un DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width        class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\", names=[\"sepal length\",\"sepal width\",\"petal length\",\"petal width\",\"class\"])\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E creiamo gli array per addestramento e test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop(\"class\",axis=1).values\n",
    "Y = iris[\"class\"].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La prima tecnica che vediamo è la Grid Search, che permette di ricercare gli iperparametri corretti con un approccio a forza bruta.<br>\n",
    "Possiamo implementare il Grid Search utilizzando la classe GridSearchCV di sklearn.<br>\n",
    "Questa classe effettua la grid search su un insieme di parametri che definiamo tramite un dizionario e valida i modelli ottenuti tramite k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iperparametri migliori: {'C': 1, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "Accuracy=0.9810\n",
      "CPU times: user 822 ms, sys: 19.4 ms, total: 841 ms\n",
      "Wall time: 882 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "param_grid = {\"kernel\": [\"linear\",\"rbf\",\"sigmoid\",\"poly\"],\n",
    "             \"C\": [1, 10, 100, 1000],\n",
    "             \"gamma\": [0.1,1,\"auto\"]}\n",
    "\n",
    "gs = GridSearchCV(svc, param_grid, cv=10) #in cv specifichiamo il numero di folds per la cross-validation\n",
    "\n",
    "gs.fit(X_train, Y_train)\n",
    "print(\"Iperparametri migliori: \"+str(gs.best_params_))\n",
    "print(\"Accuracy=%.4f\" % gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo ottenere i parametri del modello miglore tramite l'attributo best_params, ma possiamo anche ottenere direttamente il modello migliore già addestrato tramite l'attributo best_estimator_.<br>\n",
    "Recuperiamo il modello migliore trovato durante la grid search e calcoliamo l'accuracy sul test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = gs.best_estimator_\n",
    "svc.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search\n",
    "La seconda tecnica che vediamo è la Random Search, che ricerca i valori ottimali degli iperparametri cercandoli a caso in una distribuzione di valori da noi definita.<br>\n",
    "Evidenze sperimentali hanno dimostrato che questo approccio porta a risultati migliori e più velocemente.<br>\n",
    "Possiamo implementare il Grid Search utilizzando la classe GridSearchCV di sklearn.<br>\n",
    "Questa classe effettua la grid search su un insieme di parametri che definiamo tramite un dizionario e valida i modelli ottenuti tramite k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iperparametri migliori: {'kernel': 'linear', 'gamma': 0.1, 'C': 1}\n",
      "Accuracy=0.9810\n",
      "CPU times: user 173 ms, sys: 2.51 ms, total: 176 ms\n",
      "Wall time: 174 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "param_dist = {\"kernel\": [\"linear\",\"rbf\",\"sigmoid\",\"poly\"],\n",
    "             \"C\": [1, 10, 100, 1000],\n",
    "             \"gamma\": [0.1,1,\"auto\"]}\n",
    "\n",
    "rs = RandomizedSearchCV(svc, param_dist, cv=10)\n",
    "\n",
    "rs.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Iperparametri migliori: \"+str(rs.best_params_))\n",
    "print(\"Accuracy=%.4f\" % rs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La Random Search ha trovato il modello migliore in meno di un quinto del tempo della Grid Search.<br>\n",
    "Recuperiamo il modello migliore trovato durante la random search e calcoliamo l'accuracy sul test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = rs.best_estimator_\n",
    "rs.score(X_test,Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
